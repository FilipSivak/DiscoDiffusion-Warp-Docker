{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "image_morphing_3d.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN2qvMJDB2Y2gXAi8q17HBl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sxela/DiscoDiffusion-Warp/blob/main/image_morphing_3d.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DiscoDiffusion 3d Animation only mode by [Alex Spirin](https://linktr.ee/devdef) \n",
        "![visitors](https://visitor-badge.glitch.me/badge?page_id=sxela_3dmorph_colab)\n",
        "\n",
        "\n",
        "This is an amputated 3d animation mode from the awesome [DiscoDiffusion colab](https://colab.research.google.com/github/alembics/disco-diffusion/blob/main/Disco_Diffusion.ipynb#scrollTo=Changelog) \n",
        "\n",
        "\n",
        "It takes an image as an input, distorts it based on the animation settings below, and makes a video.\n"
      ],
      "metadata": {
        "id": "KnCBcp4ctDVR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1.2 Prepare Folders\n",
        "import subprocess, os, sys, ipykernel\n",
        "\n",
        "def gitclone(url):\n",
        "  res = subprocess.run(['git', 'clone', url], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "  print(res)\n",
        "\n",
        "def pipi(modulestr):\n",
        "  res = subprocess.run(['pip', 'install', modulestr], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "  print(res)\n",
        "\n",
        "def pipie(modulestr):\n",
        "  res = subprocess.run(['git', 'install', '-e', modulestr], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "  print(res)\n",
        "\n",
        "def wget(url, outputdir):\n",
        "  res = subprocess.run(['wget', url, '-P', f'{outputdir}'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "  print(res)\n",
        "\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    print(\"Google Colab detected. Using Google Drive.\")\n",
        "    is_colab = True\n",
        "    #@markdown If you connect your Google Drive, you can save the final image of each run on your drive.\n",
        "    google_drive = True #@param {type:\"boolean\"}\n",
        "    #@markdown Click here if you'd like to save the diffusion model checkpoint file to (and/or load from) your Google Drive:\n",
        "    save_models_to_google_drive = True #@param {type:\"boolean\"}\n",
        "except:\n",
        "    is_colab = False\n",
        "    google_drive = False\n",
        "    save_models_to_google_drive = False\n",
        "    print(\"Google Colab not detected.\")\n",
        "\n",
        "if is_colab:\n",
        "    if google_drive is True:\n",
        "        drive.mount('/content/drive')\n",
        "        root_path = '/content/drive/MyDrive/AI/Disco_Diffusion'\n",
        "    else:\n",
        "        root_path = '/content'\n",
        "else:\n",
        "    root_path = os.getcwd()\n",
        "\n",
        "import os\n",
        "def createPath(filepath):\n",
        "    os.makedirs(filepath, exist_ok=True)\n",
        "\n",
        "initDirPath = f'{root_path}/init_images'\n",
        "createPath(initDirPath)\n",
        "outDirPath = f'{root_path}/images_out'\n",
        "createPath(outDirPath)\n",
        "\n",
        "if is_colab:\n",
        "    if google_drive and not save_models_to_google_drive or not google_drive:\n",
        "        model_path = '/content/models'\n",
        "        createPath(model_path)\n",
        "    if google_drive and save_models_to_google_drive:\n",
        "        model_path = f'{root_path}/models'\n",
        "        createPath(model_path)\n",
        "else:\n",
        "    model_path = f'{root_path}/models'\n",
        "    createPath(model_path)\n",
        "\n",
        "# libraries = f'{root_path}/libraries'\n",
        "# createPath(libraries)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S65d1tI_RfEL",
        "outputId": "bdeed52b-fdcf-4e86-8825-3d25c9447271",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google Colab detected. Using Google Drive.\n",
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ### 1.3 Install and import dependencies\n",
        "\n",
        "import pathlib, shutil, os, sys\n",
        "\n",
        "if not is_colab:\n",
        "  # If running locally, there's a good chance your env will need this in order to not crash upon np.matmul() or similar operations.\n",
        "  os.environ['KMP_DUPLICATE_LIB_OK']='TRUE'\n",
        "\n",
        "PROJECT_DIR = os.path.abspath(os.getcwd())\n",
        "USE_ADABINS = True\n",
        "\n",
        "if is_colab:\n",
        "  if google_drive is not True:\n",
        "    root_path = f'/content'\n",
        "    model_path = '/content/models' \n",
        "else:\n",
        "  root_path = os.getcwd()\n",
        "  model_path = f'{root_path}/models'\n",
        "\n",
        "model_256_downloaded = False\n",
        "model_512_downloaded = False\n",
        "model_secondary_downloaded = False\n",
        "\n",
        "multipip_res = subprocess.run(['pip', 'install', 'lpips', 'datetime', 'timm', 'ftfy', 'einops', 'pytorch-lightning', 'omegaconf'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "print(multipip_res)\n",
        "\n",
        "if is_colab:\n",
        "  subprocess.run(['apt', 'install', 'imagemagick'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "\n",
        "# try:\n",
        "#   from CLIP import clip\n",
        "# except:\n",
        "#   if not os.path.exists(\"CLIP\"):\n",
        "#     gitclone(\"https://github.com/openai/CLIP\")\n",
        "#   sys.path.append(f'{PROJECT_DIR}/CLIP')\n",
        "\n",
        "# try:\n",
        "#   from guided_diffusion.script_util import create_model_and_diffusion\n",
        "# except:\n",
        "#   if not os.path.exists(\"guided-diffusion\"):\n",
        "#     gitclone(\"https://github.com/crowsonkb/guided-diffusion\")\n",
        "#   sys.path.append(f'{PROJECT_DIR}/guided-diffusion')\n",
        "\n",
        "# try:\n",
        "#   from resize_right import resize\n",
        "# except:\n",
        "#   if not os.path.exists(\"ResizeRight\"):\n",
        "#     gitclone(\"https://github.com/assafshocher/ResizeRight.git\")\n",
        "#   sys.path.append(f'{PROJECT_DIR}/ResizeRight')\n",
        "\n",
        "try:\n",
        "  import py3d_tools\n",
        "except:\n",
        "  if not os.path.exists('pytorch3d-lite'):\n",
        "    gitclone(\"https://github.com/MSFTserver/pytorch3d-lite.git\")\n",
        "  sys.path.append(f'{PROJECT_DIR}/pytorch3d-lite')\n",
        "\n",
        "try:\n",
        "  from midas.dpt_depth import DPTDepthModel\n",
        "except:\n",
        "  if not os.path.exists('MiDaS'):\n",
        "    gitclone(\"https://github.com/isl-org/MiDaS.git\")\n",
        "  if not os.path.exists('MiDaS/midas_utils.py'):\n",
        "    shutil.move('MiDaS/utils.py', 'MiDaS/midas_utils.py')\n",
        "  if not os.path.exists(f'{model_path}/dpt_large-midas-2f21e586.pt'):\n",
        "    wget(\"https://github.com/intel-isl/DPT/releases/download/1_0/dpt_large-midas-2f21e586.pt\", model_path)\n",
        "  sys.path.append(f'{PROJECT_DIR}/MiDaS')\n",
        "\n",
        "try:\n",
        "  sys.path.append(PROJECT_DIR)\n",
        "  import disco_xform_utils as dxf\n",
        "except:\n",
        "  if not os.path.exists(\"disco-diffusion\"):\n",
        "    gitclone(\"https://github.com/alembics/disco-diffusion.git\")\n",
        "  if os.path.exists('disco_xform_utils.py') is not True:\n",
        "    shutil.move('disco-diffusion/disco_xform_utils.py', 'disco_xform_utils.py')\n",
        "  sys.path.append(PROJECT_DIR)\n",
        "\n",
        "import torch\n",
        "from dataclasses import dataclass\n",
        "from functools import partial\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import gc\n",
        "import io\n",
        "import math\n",
        "import timm\n",
        "from IPython import display\n",
        "import lpips\n",
        "from PIL import Image, ImageOps\n",
        "import requests\n",
        "from glob import glob\n",
        "import json\n",
        "from types import SimpleNamespace\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "import torchvision.transforms as T\n",
        "import torchvision.transforms.functional as TF\n",
        "from tqdm.notebook import tqdm\n",
        "# from CLIP import clip\n",
        "# from resize_right import resize\n",
        "# from guided_diffusion.script_util import create_model_and_diffusion, model_and_diffusion_defaults\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from ipywidgets import Output\n",
        "import hashlib\n",
        "from functools import partial\n",
        "if is_colab:\n",
        "  os.chdir('/content')\n",
        "  from google.colab import files\n",
        "else:\n",
        "  os.chdir(f'{PROJECT_DIR}')\n",
        "from IPython.display import Image as ipyimg\n",
        "from numpy import asarray\n",
        "from einops import rearrange, repeat\n",
        "import torch, torchvision\n",
        "import time\n",
        "from omegaconf import OmegaConf\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "# AdaBins stuff\n",
        "if USE_ADABINS:\n",
        "  try:\n",
        "    from infer import InferenceHelper\n",
        "  except:\n",
        "    if os.path.exists(\"AdaBins\") is not True:\n",
        "      gitclone(\"https://github.com/shariqfarooq123/AdaBins.git\")\n",
        "    if not os.path.exists(f'{PROJECT_DIR}/pretrained/AdaBins_nyu.pt'):\n",
        "      createPath(f'{PROJECT_DIR}/pretrained')\n",
        "      wget(\"https://cloudflare-ipfs.com/ipfs/Qmd2mMnDLWePKmgfS8m6ntAg4nhV5VkUyAydYBp8cWWeB7/AdaBins_nyu.pt\", f'{PROJECT_DIR}/pretrained')\n",
        "    sys.path.append(f'{PROJECT_DIR}/AdaBins')\n",
        "  from infer import InferenceHelper\n",
        "  MAX_ADABINS_AREA = 500000\n",
        "\n",
        "import torch\n",
        "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', DEVICE)\n",
        "device = DEVICE # At least one of the modules expects this name..\n",
        "\n",
        "if torch.cuda.get_device_capability(DEVICE) == (8,0): ## A100 fix thanks to Emad\n",
        "  print('Disabling CUDNN for A100 gpu', file=sys.stderr)\n",
        "  torch.backends.cudnn.enabled = False"
      ],
      "metadata": {
        "id": "UZSVli6h_V_Q",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ####**Animation Mode:**\n",
        "animation_mode = '3D'\n",
        "#@markdown *For animation, you probably want to turn `cutn_batches` to 1 to make it quicker.*\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if is_colab:\n",
        "    video_init_path = \"/content/training.mp4\" \n",
        "else:\n",
        "    video_init_path = \"training.mp4\"\n",
        "extract_nth_frame = 2 \n",
        "video_init_seed_continuity = True\n",
        "\n",
        "if animation_mode == \"Video Input\":\n",
        "  if is_colab:\n",
        "      videoFramesFolder = f'/content/videoFrames'\n",
        "  else:\n",
        "      videoFramesFolder = f'videoFrames'\n",
        "  createPath(videoFramesFolder)\n",
        "  print(f\"Exporting Video Frames (1 every {extract_nth_frame})...\")\n",
        "  try:\n",
        "    for f in pathlib.Path(f'{videoFramesFolder}').glob('*.jpg'):\n",
        "      f.unlink()\n",
        "  except:\n",
        "    print('')\n",
        "  vf = f'select=not(mod(n\\,{extract_nth_frame}))'\n",
        "  subprocess.run(['ffmpeg', '-i', f'{video_init_path}', '-vf', f'{vf}', '-vsync', 'vfr', '-q:v', '2', '-loglevel', 'error', '-stats', f'{videoFramesFolder}/%04d.jpg'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "  #!ffmpeg -i {video_init_path} -vf {vf} -vsync vfr -q:v 2 -loglevel error -stats {videoFramesFolder}/%04d.jpg\n",
        "\n",
        "key_frames = True \n",
        "max_frames = 10000\n",
        "\n",
        "if animation_mode == \"Video Input\":\n",
        "  max_frames = len(glob(f'{videoFramesFolder}/*.jpg'))\n",
        "\n",
        "interp_spline = 'Linear' #Do not change, currently will not look good. param ['Linear','Quadratic','Cubic']{type:\"string\"}\n",
        "angle = \"0:(0)\"#@param {type:\"string\"}\n",
        "zoom = \"0: (1)\"#@param {type:\"string\"}\n",
        "translation_x = \"0: (1.25)\"#@param {type:\"string\"}\n",
        "translation_y = \"0: (0)\"#@param {type:\"string\"}\n",
        "translation_z = \"0: (.5)\"#@param {type:\"string\"}\n",
        "rotation_3d_x = \"0: (0)\"#@param {type:\"string\"}\n",
        "rotation_3d_y = \"0: (-0.125)\"#@param {type:\"string\"}\n",
        "rotation_3d_z = \"0: (0)\"#@param {type:\"string\"}\n",
        "midas_depth_model = \"dpt_large\"#@param {type:\"string\"}\n",
        "midas_weight = 0.8#@param {type:\"number\"}\n",
        "near_plane = 200#@param {type:\"number\"}\n",
        "far_plane = 10000#@param {type:\"number\"}\n",
        "fov = 120#@param {type:\"number\"}\n",
        "padding_mode = 'border'#@param {type:\"string\"}\n",
        "sampling_mode = 'bicubic'#@param {type:\"string\"}\n",
        "\n",
        "\n",
        "turbo_mode = False\n",
        "turbo_steps = \"3\" \n",
        "turbo_preroll = 10\n",
        "\n",
        "#insist turbo be used only w 3d anim.\n",
        "if turbo_mode and animation_mode != '3D':\n",
        "  print('=====')\n",
        "  print('Turbo mode only available with 3D animations. Disabling Turbo.')\n",
        "  print('=====')\n",
        "  turbo_mode = False\n",
        "\n",
        "\n",
        "frames_scale = 1500\n",
        "frames_skip_steps = '60%' \n",
        "\n",
        "vr_mode = False \n",
        "vr_eye_angle = 0.5\n",
        "vr_ipd = 5.0 \n",
        "\n",
        "#insist VR be used only w 3d anim.\n",
        "if vr_mode and animation_mode != '3D':\n",
        "  print('=====')\n",
        "  print('VR mode only available with 3D animations. Disabling VR.')\n",
        "  print('=====')\n",
        "  vr_mode = False\n",
        "\n",
        "\n",
        "def parse_key_frames(string, prompt_parser=None):\n",
        "    \"\"\"Given a string representing frame numbers paired with parameter values at that frame,\n",
        "    return a dictionary with the frame numbers as keys and the parameter values as the values.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    string: string\n",
        "        Frame numbers paired with parameter values at that frame number, in the format\n",
        "        'framenumber1: (parametervalues1), framenumber2: (parametervalues2), ...'\n",
        "    prompt_parser: function or None, optional\n",
        "        If provided, prompt_parser will be applied to each string of parameter values.\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    dict\n",
        "        Frame numbers as keys, parameter values at that frame number as values\n",
        "\n",
        "    Raises\n",
        "    ------\n",
        "    RuntimeError\n",
        "        If the input string does not match the expected format.\n",
        "    \n",
        "    Examples\n",
        "    --------\n",
        "    >>> parse_key_frames(\"10:(Apple: 1| Orange: 0), 20: (Apple: 0| Orange: 1| Peach: 1)\")\n",
        "    {10: 'Apple: 1| Orange: 0', 20: 'Apple: 0| Orange: 1| Peach: 1'}\n",
        "\n",
        "    >>> parse_key_frames(\"10:(Apple: 1| Orange: 0), 20: (Apple: 0| Orange: 1| Peach: 1)\", prompt_parser=lambda x: x.lower()))\n",
        "    {10: 'apple: 1| orange: 0', 20: 'apple: 0| orange: 1| peach: 1'}\n",
        "    \"\"\"\n",
        "    import re\n",
        "    pattern = r'((?P<frame>[0-9]+):[\\s]*[\\(](?P<param>[\\S\\s]*?)[\\)])'\n",
        "    frames = dict()\n",
        "    for match_object in re.finditer(pattern, string):\n",
        "        frame = int(match_object.groupdict()['frame'])\n",
        "        param = match_object.groupdict()['param']\n",
        "        if prompt_parser:\n",
        "            frames[frame] = prompt_parser(param)\n",
        "        else:\n",
        "            frames[frame] = param\n",
        "\n",
        "    if frames == {} and len(string) != 0:\n",
        "        raise RuntimeError('Key Frame string not correctly formatted')\n",
        "    return frames\n",
        "\n",
        "def get_inbetweens(key_frames, integer=False):\n",
        "    \"\"\"Given a dict with frame numbers as keys and a parameter value as values,\n",
        "    return a pandas Series containing the value of the parameter at every frame from 0 to max_frames.\n",
        "    Any values not provided in the input dict are calculated by linear interpolation between\n",
        "    the values of the previous and next provided frames. If there is no previous provided frame, then\n",
        "    the value is equal to the value of the next provided frame, or if there is no next provided frame,\n",
        "    then the value is equal to the value of the previous provided frame. If no frames are provided,\n",
        "    all frame values are NaN.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    key_frames: dict\n",
        "        A dict with integer frame numbers as keys and numerical values of a particular parameter as values.\n",
        "    integer: Bool, optional\n",
        "        If True, the values of the output series are converted to integers.\n",
        "        Otherwise, the values are floats.\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    pd.Series\n",
        "        A Series with length max_frames representing the parameter values for each frame.\n",
        "    \n",
        "    Examples\n",
        "    --------\n",
        "    >>> max_frames = 5\n",
        "    >>> get_inbetweens({1: 5, 3: 6})\n",
        "    0    5.0\n",
        "    1    5.0\n",
        "    2    5.5\n",
        "    3    6.0\n",
        "    4    6.0\n",
        "    dtype: float64\n",
        "\n",
        "    >>> get_inbetweens({1: 5, 3: 6}, integer=True)\n",
        "    0    5\n",
        "    1    5\n",
        "    2    5\n",
        "    3    6\n",
        "    4    6\n",
        "    dtype: int64\n",
        "    \"\"\"\n",
        "    key_frame_series = pd.Series([np.nan for a in range(max_frames)])\n",
        "\n",
        "    for i, value in key_frames.items():\n",
        "        key_frame_series[i] = value\n",
        "    key_frame_series = key_frame_series.astype(float)\n",
        "    \n",
        "    interp_method = interp_spline\n",
        "\n",
        "    if interp_method == 'Cubic' and len(key_frames.items()) <=3:\n",
        "      interp_method = 'Quadratic'\n",
        "    \n",
        "    if interp_method == 'Quadratic' and len(key_frames.items()) <= 2:\n",
        "      interp_method = 'Linear'\n",
        "      \n",
        "    \n",
        "    key_frame_series[0] = key_frame_series[key_frame_series.first_valid_index()]\n",
        "    key_frame_series[max_frames-1] = key_frame_series[key_frame_series.last_valid_index()]\n",
        "    # key_frame_series = key_frame_series.interpolate(method=intrp_method,order=1, limit_direction='both')\n",
        "    key_frame_series = key_frame_series.interpolate(method=interp_method.lower(),limit_direction='both')\n",
        "    if integer:\n",
        "        return key_frame_series.astype(int)\n",
        "    return key_frame_series\n",
        "\n",
        "def split_prompts(prompts):\n",
        "  prompt_series = pd.Series([np.nan for a in range(max_frames)])\n",
        "  for i, prompt in prompts.items():\n",
        "    prompt_series[i] = prompt\n",
        "  # prompt_series = prompt_series.astype(str)\n",
        "  prompt_series = prompt_series.ffill().bfill()\n",
        "  return prompt_series\n",
        "\n",
        "if key_frames:\n",
        "    try:\n",
        "        angle_series = get_inbetweens(parse_key_frames(angle))\n",
        "    except RuntimeError as e:\n",
        "        print(\n",
        "            \"WARNING: You have selected to use key frames, but you have not \"\n",
        "            \"formatted `angle` correctly for key frames.\\n\"\n",
        "            \"Attempting to interpret `angle` as \"\n",
        "            f'\"0: ({angle})\"\\n'\n",
        "            \"Please read the instructions to find out how to use key frames \"\n",
        "            \"correctly.\\n\"\n",
        "        )\n",
        "        angle = f\"0: ({angle})\"\n",
        "        angle_series = get_inbetweens(parse_key_frames(angle))\n",
        "\n",
        "    try:\n",
        "        zoom_series = get_inbetweens(parse_key_frames(zoom))\n",
        "    except RuntimeError as e:\n",
        "        print(\n",
        "            \"WARNING: You have selected to use key frames, but you have not \"\n",
        "            \"formatted `zoom` correctly for key frames.\\n\"\n",
        "            \"Attempting to interpret `zoom` as \"\n",
        "            f'\"0: ({zoom})\"\\n'\n",
        "            \"Please read the instructions to find out how to use key frames \"\n",
        "            \"correctly.\\n\"\n",
        "        )\n",
        "        zoom = f\"0: ({zoom})\"\n",
        "        zoom_series = get_inbetweens(parse_key_frames(zoom))\n",
        "\n",
        "    try:\n",
        "        translation_x_series = get_inbetweens(parse_key_frames(translation_x))\n",
        "    except RuntimeError as e:\n",
        "        print(\n",
        "            \"WARNING: You have selected to use key frames, but you have not \"\n",
        "            \"formatted `translation_x` correctly for key frames.\\n\"\n",
        "            \"Attempting to interpret `translation_x` as \"\n",
        "            f'\"0: ({translation_x})\"\\n'\n",
        "            \"Please read the instructions to find out how to use key frames \"\n",
        "            \"correctly.\\n\"\n",
        "        )\n",
        "        translation_x = f\"0: ({translation_x})\"\n",
        "        translation_x_series = get_inbetweens(parse_key_frames(translation_x))\n",
        "\n",
        "    try:\n",
        "        translation_y_series = get_inbetweens(parse_key_frames(translation_y))\n",
        "    except RuntimeError as e:\n",
        "        print(\n",
        "            \"WARNING: You have selected to use key frames, but you have not \"\n",
        "            \"formatted `translation_y` correctly for key frames.\\n\"\n",
        "            \"Attempting to interpret `translation_y` as \"\n",
        "            f'\"0: ({translation_y})\"\\n'\n",
        "            \"Please read the instructions to find out how to use key frames \"\n",
        "            \"correctly.\\n\"\n",
        "        )\n",
        "        translation_y = f\"0: ({translation_y})\"\n",
        "        translation_y_series = get_inbetweens(parse_key_frames(translation_y))\n",
        "\n",
        "    try:\n",
        "        translation_z_series = get_inbetweens(parse_key_frames(translation_z))\n",
        "    except RuntimeError as e:\n",
        "        print(\n",
        "            \"WARNING: You have selected to use key frames, but you have not \"\n",
        "            \"formatted `translation_z` correctly for key frames.\\n\"\n",
        "            \"Attempting to interpret `translation_z` as \"\n",
        "            f'\"0: ({translation_z})\"\\n'\n",
        "            \"Please read the instructions to find out how to use key frames \"\n",
        "            \"correctly.\\n\"\n",
        "        )\n",
        "        translation_z = f\"0: ({translation_z})\"\n",
        "        translation_z_series = get_inbetweens(parse_key_frames(translation_z))\n",
        "\n",
        "    try:\n",
        "        rotation_3d_x_series = get_inbetweens(parse_key_frames(rotation_3d_x))\n",
        "    except RuntimeError as e:\n",
        "        print(\n",
        "            \"WARNING: You have selected to use key frames, but you have not \"\n",
        "            \"formatted `rotation_3d_x` correctly for key frames.\\n\"\n",
        "            \"Attempting to interpret `rotation_3d_x` as \"\n",
        "            f'\"0: ({rotation_3d_x})\"\\n'\n",
        "            \"Please read the instructions to find out how to use key frames \"\n",
        "            \"correctly.\\n\"\n",
        "        )\n",
        "        rotation_3d_x = f\"0: ({rotation_3d_x})\"\n",
        "        rotation_3d_x_series = get_inbetweens(parse_key_frames(rotation_3d_x))\n",
        "\n",
        "    try:\n",
        "        rotation_3d_y_series = get_inbetweens(parse_key_frames(rotation_3d_y))\n",
        "    except RuntimeError as e:\n",
        "        print(\n",
        "            \"WARNING: You have selected to use key frames, but you have not \"\n",
        "            \"formatted `rotation_3d_y` correctly for key frames.\\n\"\n",
        "            \"Attempting to interpret `rotation_3d_y` as \"\n",
        "            f'\"0: ({rotation_3d_y})\"\\n'\n",
        "            \"Please read the instructions to find out how to use key frames \"\n",
        "            \"correctly.\\n\"\n",
        "        )\n",
        "        rotation_3d_y = f\"0: ({rotation_3d_y})\"\n",
        "        rotation_3d_y_series = get_inbetweens(parse_key_frames(rotation_3d_y))\n",
        "\n",
        "    try:\n",
        "        rotation_3d_z_series = get_inbetweens(parse_key_frames(rotation_3d_z))\n",
        "    except RuntimeError as e:\n",
        "        print(\n",
        "            \"WARNING: You have selected to use key frames, but you have not \"\n",
        "            \"formatted `rotation_3d_z` correctly for key frames.\\n\"\n",
        "            \"Attempting to interpret `rotation_3d_z` as \"\n",
        "            f'\"0: ({rotation_3d_z})\"\\n'\n",
        "            \"Please read the instructions to find out how to use key frames \"\n",
        "            \"correctly.\\n\"\n",
        "        )\n",
        "        rotation_3d_z = f\"0: ({rotation_3d_z})\"\n",
        "        rotation_3d_z_series = get_inbetweens(parse_key_frames(rotation_3d_z))\n",
        "\n",
        "else:\n",
        "    angle = float(angle)\n",
        "    zoom = float(zoom)\n",
        "    translation_x = float(translation_x)\n",
        "    translation_y = float(translation_y)\n",
        "    translation_z = float(translation_z)\n",
        "    rotation_3d_x = float(rotation_3d_x)\n",
        "    rotation_3d_y = float(rotation_3d_y)\n",
        "    rotation_3d_z = float(rotation_3d_z)\n",
        "\n",
        "#@title Default title text\n",
        "args = {\n",
        "    # 'batchNum': batchNum,\n",
        "    # 'prompts_series':split_prompts(text_prompts) if text_prompts else None,\n",
        "    # 'image_prompts_series':split_prompts(image_prompts) if image_prompts else None,\n",
        "    # 'seed': seed,\n",
        "    # 'display_rate':display_rate,\n",
        "    # 'n_batches':n_batches if animation_mode == 'None' else 1,\n",
        "    # 'batch_size':batch_size,\n",
        "    # 'batch_name': batch_name,\n",
        "    # 'steps': steps,\n",
        "    # 'diffusion_sampling_mode': diffusion_sampling_mode,\n",
        "    # 'width_height': width_height,\n",
        "    # 'clip_guidance_scale': clip_guidance_scale,\n",
        "    # 'tv_scale': tv_scale,\n",
        "    # 'range_scale': range_scale,\n",
        "    # 'sat_scale': sat_scale,\n",
        "    # 'cutn_batches': cutn_batches,\n",
        "    # 'init_image': init_image,\n",
        "    # 'init_scale': init_scale,\n",
        "    # 'skip_steps': skip_steps,\n",
        "    # 'side_x': side_x,\n",
        "    # 'side_y': side_y,\n",
        "    # 'timestep_respacing': timestep_respacing,\n",
        "    # 'diffusion_steps': diffusion_steps,\n",
        "    'animation_mode': animation_mode,\n",
        "    'video_init_path': video_init_path,\n",
        "    'extract_nth_frame': extract_nth_frame,\n",
        "    'video_init_seed_continuity': video_init_seed_continuity,\n",
        "    'key_frames': key_frames,\n",
        "    'max_frames': max_frames if animation_mode != \"None\" else 1,\n",
        "    'interp_spline': interp_spline,\n",
        "    # 'start_frame': start_frame,\n",
        "    'angle': angle,\n",
        "    'zoom': zoom,\n",
        "    'translation_x': translation_x,\n",
        "    'translation_y': translation_y,\n",
        "    'translation_z': translation_z,\n",
        "    'rotation_3d_x': rotation_3d_x,\n",
        "    'rotation_3d_y': rotation_3d_y,\n",
        "    'rotation_3d_z': rotation_3d_z,\n",
        "    'midas_depth_model': midas_depth_model,\n",
        "    'midas_weight': midas_weight,\n",
        "    'near_plane': near_plane,\n",
        "    'far_plane': far_plane,\n",
        "    'fov': fov,\n",
        "    'padding_mode': padding_mode,\n",
        "    'sampling_mode': sampling_mode,\n",
        "    'angle_series':angle_series,\n",
        "    'zoom_series':zoom_series,\n",
        "    'translation_x_series':translation_x_series,\n",
        "    'translation_y_series':translation_y_series,\n",
        "    'translation_z_series':translation_z_series,\n",
        "    'rotation_3d_x_series':rotation_3d_x_series,\n",
        "    'rotation_3d_y_series':rotation_3d_y_series,\n",
        "    'rotation_3d_z_series':rotation_3d_z_series,\n",
        "    'frames_scale': frames_scale,\n",
        "    # 'calc_frames_skip_steps': calc_frames_skip_steps,\n",
        "    # 'skip_step_ratio': skip_step_ratio,\n",
        "    # 'calc_frames_skip_steps': calc_frames_skip_steps,\n",
        "    # 'text_prompts': text_prompts,\n",
        "    # 'image_prompts': image_prompts,\n",
        "    # 'cut_overview': eval(cut_overview),\n",
        "    # 'cut_innercut': eval(cut_innercut),\n",
        "    # 'cut_ic_pow': cut_ic_pow,\n",
        "    # 'cut_icgray_p': eval(cut_icgray_p),\n",
        "    # 'intermediate_saves': intermediate_saves,\n",
        "    # 'intermediates_in_subfolder': intermediates_in_subfolder,\n",
        "    # 'steps_per_checkpoint': steps_per_checkpoint,\n",
        "    # 'perlin_init': perlin_init,\n",
        "    # 'perlin_mode': perlin_mode,\n",
        "    # 'set_seed': set_seed,\n",
        "    # 'eta': eta,\n",
        "    # 'clamp_grad': clamp_grad,\n",
        "    # 'clamp_max': clamp_max,\n",
        "    # 'skip_augs': skip_augs,\n",
        "    # 'randomize_class': randomize_class,\n",
        "    # 'clip_denoised': clip_denoised,\n",
        "    # 'fuzzy_prompt': fuzzy_prompt,\n",
        "    # 'rand_mag': rand_mag,\n",
        "}\n",
        "\n",
        "args = SimpleNamespace(**args)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "JmMlLvD6ALqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "H_UBFv6x7G00"
      },
      "outputs": [],
      "source": [
        "#@title ### 1.4 Define Midas functions\n",
        "\n",
        "from midas.dpt_depth import DPTDepthModel\n",
        "from midas.midas_net import MidasNet\n",
        "from midas.midas_net_custom import MidasNet_small\n",
        "from midas.transforms import Resize, NormalizeImage, PrepareForNet\n",
        "\n",
        "# Initialize MiDaS depth model.\n",
        "# It remains resident in VRAM and likely takes around 2GB VRAM.\n",
        "# You could instead initialize it for each frame (and free it after each frame) to save VRAM.. but initializing it is slow.\n",
        "default_models = {\n",
        "    \"midas_v21_small\": f\"{model_path}/midas_v21_small-70d6b9c8.pt\",\n",
        "    \"midas_v21\": f\"{model_path}/midas_v21-f6b98070.pt\",\n",
        "    \"dpt_large\": f\"{model_path}/dpt_large-midas-2f21e586.pt\",\n",
        "    \"dpt_hybrid\": f\"{model_path}/dpt_hybrid-midas-501f0c75.pt\",\n",
        "    \"dpt_hybrid_nyu\": f\"{model_path}/dpt_hybrid_nyu-2ce69ec7.pt\",}\n",
        "\n",
        "\n",
        "def init_midas_depth_model(midas_model_type=\"dpt_large\", optimize=True):\n",
        "    midas_model = None\n",
        "    net_w = None\n",
        "    net_h = None\n",
        "    resize_mode = None\n",
        "    normalization = None\n",
        "\n",
        "    print(f\"Initializing MiDaS '{midas_model_type}' depth model...\")\n",
        "    # load network\n",
        "    midas_model_path = default_models[midas_model_type]\n",
        "\n",
        "    if midas_model_type == \"dpt_large\": # DPT-Large\n",
        "        midas_model = DPTDepthModel(\n",
        "            path=midas_model_path,\n",
        "            backbone=\"vitl16_384\",\n",
        "            non_negative=True,\n",
        "        )\n",
        "        net_w, net_h = 384, 384\n",
        "        resize_mode = \"minimal\"\n",
        "        normalization = NormalizeImage(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "    elif midas_model_type == \"dpt_hybrid\": #DPT-Hybrid\n",
        "        midas_model = DPTDepthModel(\n",
        "            path=midas_model_path,\n",
        "            backbone=\"vitb_rn50_384\",\n",
        "            non_negative=True,\n",
        "        )\n",
        "        net_w, net_h = 384, 384\n",
        "        resize_mode=\"minimal\"\n",
        "        normalization = NormalizeImage(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "    elif midas_model_type == \"dpt_hybrid_nyu\": #DPT-Hybrid-NYU\n",
        "        midas_model = DPTDepthModel(\n",
        "            path=midas_model_path,\n",
        "            backbone=\"vitb_rn50_384\",\n",
        "            non_negative=True,\n",
        "        )\n",
        "        net_w, net_h = 384, 384\n",
        "        resize_mode=\"minimal\"\n",
        "        normalization = NormalizeImage(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "    elif midas_model_type == \"midas_v21\":\n",
        "        midas_model = MidasNet(midas_model_path, non_negative=True)\n",
        "        net_w, net_h = 384, 384\n",
        "        resize_mode=\"upper_bound\"\n",
        "        normalization = NormalizeImage(\n",
        "            mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
        "        )\n",
        "    elif midas_model_type == \"midas_v21_small\":\n",
        "        midas_model = MidasNet_small(midas_model_path, features=64, backbone=\"efficientnet_lite3\", exportable=True, non_negative=True, blocks={'expand': True})\n",
        "        net_w, net_h = 256, 256\n",
        "        resize_mode=\"upper_bound\"\n",
        "        normalization = NormalizeImage(\n",
        "            mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
        "        )\n",
        "    else:\n",
        "        print(f\"midas_model_type '{midas_model_type}' not implemented\")\n",
        "        assert False\n",
        "\n",
        "    midas_transform = T.Compose(\n",
        "        [\n",
        "            Resize(\n",
        "                net_w,\n",
        "                net_h,\n",
        "                resize_target=None,\n",
        "                keep_aspect_ratio=True,\n",
        "                ensure_multiple_of=32,\n",
        "                resize_method=resize_mode,\n",
        "                image_interpolation_method=cv2.INTER_CUBIC,\n",
        "            ),\n",
        "            normalization,\n",
        "            PrepareForNet(),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    midas_model.eval()\n",
        "    \n",
        "    if optimize==True:\n",
        "        if DEVICE == torch.device(\"cuda\"):\n",
        "            midas_model = midas_model.to(memory_format=torch.channels_last)  \n",
        "            midas_model = midas_model.half()\n",
        "\n",
        "    midas_model.to(DEVICE)\n",
        "\n",
        "    print(f\"MiDaS '{midas_model_type}' depth model initialized.\")\n",
        "    return midas_model, midas_transform, net_w, net_h, resize_mode, normalization\n",
        "\n",
        "#@title Default title text\n",
        "def do_3d_step(img_filepath, frame_num, midas_model, midas_transform):\n",
        "  if args.key_frames:\n",
        "    translation_x = args.translation_x_series[frame_num]\n",
        "    translation_y = args.translation_y_series[frame_num]\n",
        "    translation_z = args.translation_z_series[frame_num]\n",
        "    rotation_3d_x = args.rotation_3d_x_series[frame_num]\n",
        "    rotation_3d_y = args.rotation_3d_y_series[frame_num]\n",
        "    rotation_3d_z = args.rotation_3d_z_series[frame_num]\n",
        "    # print(\n",
        "    #     f'translation_x: {translation_x}',\n",
        "    #     f'translation_y: {translation_y}',\n",
        "    #     f'translation_z: {translation_z}',\n",
        "    #     f'rotation_3d_x: {rotation_3d_x}',\n",
        "    #     f'rotation_3d_y: {rotation_3d_y}',\n",
        "    #     f'rotation_3d_z: {rotation_3d_z}',\n",
        "    # )\n",
        "\n",
        "  translate_xyz = [-translation_x*TRANSLATION_SCALE, translation_y*TRANSLATION_SCALE, -translation_z*TRANSLATION_SCALE]\n",
        "  rotate_xyz_degrees = [rotation_3d_x, rotation_3d_y, rotation_3d_z]\n",
        "  # print('translation:',translate_xyz)\n",
        "  # print('rotation:',rotate_xyz_degrees)\n",
        "  rotate_xyz = [math.radians(rotate_xyz_degrees[0]), math.radians(rotate_xyz_degrees[1]), math.radians(rotate_xyz_degrees[2])]\n",
        "  rot_mat = p3dT.euler_angles_to_matrix(torch.tensor(rotate_xyz, device=device), \"XYZ\").unsqueeze(0)\n",
        "  # print(\"rot_mat: \" + str(rot_mat))\n",
        "  next_step_pil = dxf.transform_image_3d(img_filepath, midas_model, midas_transform, DEVICE,\n",
        "                                          rot_mat, translate_xyz, args.near_plane, args.far_plane,\n",
        "                                          args.fov, padding_mode=args.padding_mode,\n",
        "                                          sampling_mode=args.sampling_mode, midas_weight=args.midas_weight)\n",
        "  return next_step_pil\n",
        "\n",
        "import py3d_tools as p3dT\n",
        "import disco_xform_utils as dxf\n",
        "from tqdm.notebook import trange\n",
        "midas_model, midas_transform, midas_net_w, midas_net_h, midas_resize_mode, midas_normalization = init_midas_depth_model(args.midas_depth_model)\n",
        "TRANSLATION_SCALE = 1.0/200.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Set image path, number of frames to make, and run this cell.\n",
        "#@markdown Output video will be saved to /content/\n",
        "from tqdm.notebook import trange\n",
        "\n",
        "image = '/content/emperor_preview_bg.png' #@param {type:\"string\"}\n",
        "max_frames = 20 #@param {type:\"number\"}\n",
        "!mkdir ./out\n",
        "!rm -rf ./out/*\n",
        "\n",
        "for i in trange(1, max_frames):\n",
        "  out = do_3d_step(image, i, midas_model, midas_transform)\n",
        "  new_fname = f'./out/frame_{i:04d}.png'\n",
        "  out.save(new_fname)\n",
        "  image = new_fname\n",
        "\n",
        "out_fname = f'/content/{init.split(\"/\")[-1]}_n{near_plane}_o{far_plane}_f{fov}_mw{midas_weight}.mp4'\n",
        "!ffmpeg -y -pattern_type glob -i \"/content/out/*.png\" \"{out_fname}\""
      ],
      "metadata": {
        "id": "65crZ7HfSkW2",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}